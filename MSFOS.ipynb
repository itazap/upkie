{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c5f1ac-6950-4edc-8c06-cb35f86b5936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451b247-6261-450b-80e6-f0f5372aa197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29efb1-484d-4d66-937f-a630e12953ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import upkie.envs\n",
    "\n",
    "\n",
    "class PIDController:\n",
    "    def __init__(self, kp, ki, kd, dt):\n",
    "        self.kp = kp  # Proportional gain\n",
    "        self.ki = ki  # Integral gain\n",
    "        self.kd = kd  # Derivative gain\n",
    "        self.last_error = 0\n",
    "        self.integral = 0\n",
    "        self.dt = dt\n",
    "\n",
    "    def calculate_control(self, current_value):\n",
    "        error = current_value\n",
    "        self.integral += error * self.dt  # dt is the time step\n",
    "        derivative = (error - self.last_error) / self.dt\n",
    "        control_signal = (\n",
    "            np.dot(self.kp, error) + np.dot(self.ki, self.integral) + np.dot(self.kd, derivative)\n",
    "        )\n",
    "        self.last_error = error\n",
    "        return control_signal\n",
    "\n",
    "    def reset(self):\n",
    "        self.last_error = 0\n",
    "        self.integral = 0\n",
    "\n",
    "\n",
    "class PController:\n",
    "    def __init__(self, kp, ki, kd, dt):\n",
    "        self.kp = np.array([10., 1., 0., 1.])\n",
    "\n",
    "    def calculate_control(self, current_value):\n",
    "        control_signal = (\n",
    "            np.dot(self.kp, current_value)\n",
    "        )\n",
    "        return control_signal\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def P(x):\n",
    "    kp = np.array([10., 1., 0., 1.])\n",
    "    return np.dot(kp, x)\n",
    "\n",
    "\n",
    "def push_balance_PID(env: upkie.envs.UpkieGroundVelocity, policy, force, check_msfos = False):\n",
    "    torso_force_in_world = np.zeros(3)\n",
    "    torso_force_in_world[0] = force\n",
    "    bullet_action = {\n",
    "        \"external_forces\": {\n",
    "            \"torso\": {\n",
    "                \"force\": torso_force_in_world,\n",
    "                \"local\": False,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    observation, _ = env.reset(seed = 42)\n",
    "    for step in range(4_400):\n",
    "        action = 0.0 * env.action_space.sample()\n",
    "        action[0] = policy.calculate_control(observation)\n",
    "        if step < 400 and step >= 200:\n",
    "            env.unwrapped.bullet_extra(bullet_action)  # call before env.step\n",
    "        \n",
    "        observation, _, terminated, truncated, _ = env.step(action)\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            observation, _ = env.reset(seed = 42)\n",
    "            policy.reset()\n",
    "            if check_msfos:\n",
    "                return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e00d05-cb15-46c7-b566-52b050995d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc862949-edb5-41da-8cd9-a5e73bde0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSFOS(env, policy):\n",
    "    force_0 = .1\n",
    "    force_1 = 1.\n",
    "    while push_balance(env, policy, force_1, check_msfos = True):\n",
    "        force_0 = force_1\n",
    "        force_1 *= 2\n",
    "    \n",
    "    max_ = force_1\n",
    "    min_ = force_0\n",
    "    force_1 = (max_ + min_) / 2\n",
    "    \n",
    "    while max_ - min_ > 1e-1:\n",
    "        if push_balance(env, policy, force_1, check_msfos = True):\n",
    "            min_ = force_1\n",
    "            force_1 = (force_1 + max_) / 2\n",
    "        else:\n",
    "            max_ = force_1\n",
    "            force_1 = (force_1 + min_) / 2\n",
    "    \n",
    "    return force_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140173d-56bd-47ba-9f10-32334b4e4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "upkie.envs.register()\n",
    "env = gym.make(\"UpkieGroundVelocity-v3\", frequency=200.0)\n",
    "policy = PIDController(np.array([20., 1., 0.1, 0.1]), np.array([.0, .0, 0, .0]), np.array([.1, 0., .1, .00]), 1 / 200.)\n",
    "print(MSFOS(env, policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c49af4-052e-4c49-a68e-b0cc1f64d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_balance(env: upkie.envs.UpkieServos, policy, force, check_msfos = False):\n",
    "    torso_force_in_world = np.zeros(3)\n",
    "    torso_force_in_world[0] = force\n",
    "    bullet_action = {\n",
    "        \"external_forces\": {\n",
    "            \"torso\": {\n",
    "                \"force\": torso_force_in_world,\n",
    "                \"local\": False,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    observation, _ = env.reset(seed = 42)\n",
    "    for step in range(4_000):\n",
    "        action, _ = policy.predict(observation, deterministic=True)\n",
    "        if step < 400 and step >= 200:\n",
    "            env.unwrapped.bullet_extra(bullet_action)  # call before env.step\n",
    "        \n",
    "        observation, _, terminated, truncated, _ = env.step(action)\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            observation, _ = env.reset(seed = 42)\n",
    "            if check_msfos:\n",
    "                return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dec33c-bf42-4e1a-9081-9a67a49784e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/andrei/Desktop/ppo_balancer\")\n",
    "sys.path.append(\"/Users/andrei/Desktop/ppo_balancer/ppo_balancer\")\n",
    "\n",
    "import gin\n",
    "config_path = \"/Users/andrei/Desktop/ppo_balancer/ppo_balancer/policy/operative_config.gin\"\n",
    "gin.parse_config_file(config_path)\n",
    "\n",
    "from settings import EnvSettings, PPOSettings, TrainingSettings\n",
    "from envs import make_ppo_balancer_env, make_ppo_balancer_env_servos\n",
    "#from train import CustomUpkieServos, UpkieServosWrapper\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "upkie.envs.register()\n",
    "\n",
    "ppo_settings = PPOSettings()\n",
    "env_settings = EnvSettings()\n",
    "init_state = None\n",
    "\n",
    "# parent process: trainer\n",
    "agent_frequency = env_settings.agent_frequency\n",
    "\n",
    "velocity_env = upkie.envs.UpkieServos(\n",
    "            frequency=agent_frequency,\n",
    "            regulate_frequency=False,\n",
    "            spine_config=env_settings.spine_config,\n",
    "        )\n",
    "\n",
    "# Wrap the environment with the UpkieServosWrapper\n",
    "velocity_env_flat = UpkieServosWrapper(velocity_env)\n",
    "\n",
    "env = make_ppo_balancer_env_servos(velocity_env_flat, env_settings, training=True)\n",
    "\n",
    "'''\n",
    "with gym.make(\n",
    "        env_settings.env_id,\n",
    "        frequency=env_settings.agent_frequency,\n",
    "        init_state=init_state,\n",
    "        max_ground_velocity=env_settings.max_ground_velocity,\n",
    "        regulate_frequency=True,\n",
    "        spine_config=env_settings.spine_config,\n",
    "    ) as velocity_env:\n",
    "        env = make_ppo_balancer_env(\n",
    "            velocity_env,\n",
    "            env_settings,\n",
    "            training=False,\n",
    "        )\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "policy = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs={\n",
    "        \"net_arch\": {\n",
    "            \"pi\": ppo_settings.net_arch_pi,\n",
    "            \"vf\": ppo_settings.net_arch_vf,\n",
    "        },\n",
    "    },\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "policy.set_parameters(\"/Users/andrei/Desktop/ppo_balancer/training/2024-12-06/prostemmate_1/final\") # Itza, toyish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc28ee-91f1-4608-9d8d-cb1bb3e4ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSFOS(env, policy))\n",
    "#push_balance(env, policy, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029c8f5-a9db-439e-9474-388220a9f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "\n",
    "class UpkieServosWrapper(gymnasium.Wrapper):\n",
    "    \"\"\"!\n",
    "    Wrapper for the UpkieServos environment that converts actions \n",
    "    and observations to NumPy ndarrays.\n",
    "\n",
    "    This wrapper simplifies the interaction with the UpkieServos environment\n",
    "    by converting the dictionary-based actions and observations into \n",
    "    flattened NumPy ndarrays. This can be useful for compatibility with \n",
    "    algorithms that expect ndarray inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env: gymnasium.Env):\n",
    "        \"\"\"!\n",
    "        Initialize the wrapper.\n",
    "\n",
    "        Args:\n",
    "            env: The UpkieServos environment to wrap.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "\n",
    "        # Determine the size of the flattened action and observation arrays\n",
    "        self.action_dim = 2\n",
    "        self.observation_dim = 3 + 2\n",
    "\n",
    "        # Determine the lower and upper bounds for the flattened action and observation spaces\n",
    "        action_low = np.array([0, -1,])#-1, 0, -1])\n",
    "        action_high = np.array([1., 1.])# 1, 1.01, 1])\n",
    "        observation_low = np.concatenate([\n",
    "            np.array([-1.26, -16., -28.8])\n",
    "            for i in range(1)\n",
    "        ] + [np.array([-2., -28.8])])\n",
    "        observation_high = np.concatenate([\n",
    "            np.array([1.26, 28.8])\n",
    "            for i in range(1)\n",
    "        ] + [np.array([2., 500., 28.8])])\n",
    "\n",
    "\n",
    "        # Define the new action and observation spaces\n",
    "        self.action_space = gymnasium.spaces.Box(\n",
    "            low=action_low, high=action_high, shape=(self.action_dim,), dtype=np.float64\n",
    "        )\n",
    "        self.observation_space = gymnasium.spaces.Box(\n",
    "            low=observation_low,\n",
    "            high=observation_high,\n",
    "            shape=(self.observation_dim,),\n",
    "            dtype=np.float64,\n",
    "        )\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"!\n",
    "        Reset the environment and return the observation as an ndarray.\n",
    "\n",
    "        Returns:\n",
    "            The initial observation as an ndarray.\n",
    "        \"\"\"\n",
    "        obs_dict, info = self.env.reset(seed=seed, options=options)\n",
    "        obs_dict[\"pitch\"] = info[\"spine_observation\"][\"base_orientation\"][\"pitch\"]\n",
    "        obs_dict[\"velocity\"] = info[\"spine_observation\"][\"wheel_odometry\"][\"velocity\"]\n",
    "        obs_dict[\"pitch_vel\"] = np.linalg.norm(info[\"spine_observation\"][\"imu\"][\"angular_velocity\"])\n",
    "        \n",
    "        return self._flatten_observation(obs_dict), info\n",
    "\n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"!\n",
    "        Take a step in the environment using an ndarray action.\n",
    "\n",
    "        Args:\n",
    "            action: The action to take as an ndarray.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the next observation as an ndarray,\n",
    "            the reward, a boolean indicating if the episode is done,\n",
    "            a boolean indicating if the episode is truncated,\n",
    "            and a dictionary containing extra information.\n",
    "        \"\"\"\n",
    "        action_dict = self._unflatten_action(action)\n",
    "        obs_dict, reward, terminated, truncated, info = self.env.step(\n",
    "            action_dict\n",
    "        )\n",
    "        \n",
    "        obs_dict[\"pitch\"] = info[\"spine_observation\"][\"base_orientation\"][\"pitch\"]\n",
    "        obs_dict[\"velocity\"] = info[\"spine_observation\"][\"wheel_odometry\"][\"velocity\"]\n",
    "        obs_dict[\"pitch_vel\"] = np.linalg.norm(info[\"spine_observation\"][\"imu\"][\"angular_velocity\"])\n",
    "        reward = self.get_reward(obs_dict, action_dict, pos = info[\"spine_observation\"][\"wheel_odometry\"][\"position\"], height = info[\"spine_observation\"][\"sim\"][\"base\"][\"position\"][2])\n",
    "\n",
    "        if info[\"spine_observation\"][\"sim\"][\"base\"][\"position\"][2] < 0.2 or abs(obs_dict[\"left_knee\"][\"position\"]) > 2:\n",
    "            terminated = True\n",
    "        \n",
    "        return (\n",
    "            self._flatten_observation(obs_dict),\n",
    "            reward,\n",
    "            terminated,\n",
    "            truncated,\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def flatten_action(self, action_dict: dict) -> np.ndarray:\n",
    "        \"\"\"!\n",
    "        Flatten the dictionary-based action into an ndarray.\n",
    "    \n",
    "        Args:\n",
    "            action_dict: The action dictionary.\n",
    "    \n",
    "        Returns:\n",
    "            The flattened action as an ndarray.\n",
    "        \"\"\"\n",
    "        flat_action = np.array([action_dict[\"left_knee\"][\"position\"], action_dict[\"left_wheel\"][\"velocity\"]])\n",
    "\n",
    "        return flat_action\n",
    "\n",
    "    def _flatten_observation(self, obs_dict: dict) -> np.ndarray:\n",
    "        \"\"\"!\n",
    "        Flatten the dictionary-based observation into an ndarray.\n",
    "\n",
    "        Args:\n",
    "            obs_dict: The observation dictionary.\n",
    "\n",
    "        Returns:\n",
    "            The flattened observation as an ndarray.\n",
    "        \"\"\"\n",
    "        flat_obs = []\n",
    "        for joint_obs_key in obs_dict.keys():\n",
    "            if joint_obs_key != \"pitch\" and joint_obs_key != \"velocity\" and joint_obs_key != \"pitch_vel\":\n",
    "                if joint_obs_key == \"left_knee\":    \n",
    "                    for obs_key in obs_dict[joint_obs_key].keys():\n",
    "                        obs_value = obs_dict[joint_obs_key][obs_key]\n",
    "                        if obs_key != \"temperature\" and obs_key != \"voltage\" and obs_key != \"torque\":\n",
    "                            flat_obs.append(np.array(obs_value))\n",
    "            else:\n",
    "                flat_obs.append(np.ones(1) * obs_dict[joint_obs_key])\n",
    "\n",
    "        \n",
    "        return np.concatenate(flat_obs)\n",
    "\n",
    "    def _unflatten_action(self, action_ndarray: np.ndarray) -> dict:\n",
    "        \"\"\"!\n",
    "        Unflatten the ndarray action into a dictionary-based action.\n",
    "\n",
    "        Args:\n",
    "            action_ndarray: The action as an ndarray.\n",
    "\n",
    "        Returns:\n",
    "            The unflattened action as a dictionary.\n",
    "        \"\"\"\n",
    "        action_dict = {}\n",
    "        i = 0\n",
    "        for joint_name, joint_space in self.env.action_space.spaces.items():\n",
    "            action_dict[joint_name] = {}\n",
    "            if joint_name == \"left_hip\":\n",
    "                action_dict[joint_name][\"velocity\"] = 0\n",
    "                action_dict[joint_name][\"feedforward_torque\"] = 0\n",
    "                action_dict[joint_name][\"kd_scale\"] = 1.\n",
    "                action_dict[joint_name][\"kp_scale\"] = 1.\n",
    "                action_dict[joint_name][\"position\"] = - action_ndarray[0] / 2\n",
    "            elif joint_name == \"left_knee\":\n",
    "                action_dict[joint_name][\"velocity\"] = 0\n",
    "                action_dict[joint_name][\"feedforward_torque\"] = 0\n",
    "                action_dict[joint_name][\"kd_scale\"] = 1.\n",
    "                action_dict[joint_name][\"kp_scale\"] = 1.\n",
    "                action_dict[joint_name][\"position\"] = action_ndarray[0]\n",
    "            elif joint_name == \"left_wheel\":\n",
    "                action_dict[joint_name][\"position\"] = np.nan\n",
    "                action_dict[joint_name][\"feedforward_torque\"] = 0\n",
    "                action_dict[joint_name][\"kd_scale\"] = 1.\n",
    "                action_dict[joint_name][\"kp_scale\"] = 1.\n",
    "                action_dict[joint_name][\"velocity\"] = action_ndarray[1] * 28.8\n",
    "            elif joint_name == \"right_hip\":\n",
    "                action_dict[joint_name][\"position\"] = action_ndarray[0] / 2\n",
    "                action_dict[joint_name][\"feedforward_torque\"] = 0\n",
    "                action_dict[joint_name][\"kd_scale\"] = 1.\n",
    "                action_dict[joint_name][\"kp_scale\"] = 1.\n",
    "                action_dict[joint_name][\"velocity\"] = 0\n",
    "            elif joint_name == \"right_knee\":\n",
    "                action_dict[joint_name][\"position\"] = -action_ndarray[0]\n",
    "                action_dict[joint_name][\"feedforward_torque\"] = 0\n",
    "                action_dict[joint_name][\"kd_scale\"] = 1.\n",
    "                action_dict[joint_name][\"kp_scale\"] = 1.\n",
    "                action_dict[joint_name][\"velocity\"] = 0\n",
    "            elif joint_name == \"right_wheel\":\n",
    "                action_dict[joint_name][\"position\"] = np.nan\n",
    "                action_dict[joint_name][\"feedforward_torque\"] = 0\n",
    "                action_dict[joint_name][\"kd_scale\"] = 1.\n",
    "                action_dict[joint_name][\"kp_scale\"] = 1.\n",
    "                action_dict[joint_name][\"velocity\"] = -action_ndarray[1] * 28.8\n",
    "        return action_dict\n",
    "    \n",
    "    # Override the method that calculates the reward.\n",
    "    def get_reward(self, observation: dict, action: dict, pos: float, height: float) -> float:\n",
    "        \"\"\"!\n",
    "        Get reward from observation and action.\n",
    "\n",
    "        \\param observation Environment observation.\n",
    "        \\param action Environment action.\n",
    "        \\return Reward.\n",
    "        \"\"\"\n",
    "        estimated_pitch = observation[\"pitch\"]\n",
    "        estimated_ground_position = pos\n",
    "        estimated_ground_velocity = observation[\"velocity\"]\n",
    "        estimated_height = height\n",
    "        estimated_angular_velocity = observation[\"pitch_vel\"]\n",
    "\n",
    "\n",
    "        tip_height = 0.58  # [m]  # This might need adjustment for the Upkie robot\n",
    "        tip_position = estimated_ground_position + tip_height * np.sin(estimated_pitch)\n",
    "        tip_velocity = estimated_ground_velocity + tip_height * estimated_angular_velocity * np.cos(estimated_pitch)\n",
    "\n",
    "        std_position = 0.05  # [m]\n",
    "        position_reward = np.exp(-((tip_position / std_position) ** 2))\n",
    "        velocity_penalty = -abs(tip_velocity)\n",
    "\n",
    "        position_weight = 1.0  # You can adjust these weights\n",
    "        velocity_weight = 0.1\n",
    "\n",
    "        ## Shaping\n",
    "        wheel_velocity_penalty = -abs(observation[\"left_wheel\"][\"velocity\"])\n",
    "        wheel_velocity_weight = 0.1\n",
    "        height_reward = estimated_height > 0.3\n",
    "        height_weight = 0.0\n",
    "\n",
    "        return 0.5 + position_weight * position_reward + velocity_weight * velocity_penalty + height_reward * height_weight + wheel_velocity_penalty * wheel_velocity_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe047152-5eeb-49b9-816e-7dd59e53450b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
